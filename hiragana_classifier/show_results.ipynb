{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368a75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 01:21:13.873101: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 01:21:15.834606: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.d6f03b303ac3c4f2eeb8ca631688c9757b361310.so\n",
      "2022-12-22 01:21:15.834665: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2022-12-22 01:21:15.837221: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "2022-12-22 01:21:16.157261: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "from model import EfficientHiragana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c470f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "BATCH_SIZE=512\n",
    "IMG_SIZE=48\n",
    "\n",
    "# load images\n",
    "PATH = '/mnt/c/Users/44yos/Hiragana/hiragana_classifier' # os.path.dirname(os.path.realpath(__file__))\n",
    "data_dir = os.path.join(PATH, 'datasets')\n",
    "datasets = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    shuffle=True,\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    ")\n",
    "\n",
    "# train / test split\n",
    "all_batches = tf.data.experimental.cardinality(datasets)\n",
    "test_dataset = datasets.take(all_batches // 10)\n",
    "train_dataset = datasets.skip(all_batches // 10)\n",
    "\n",
    "# prefetch\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# create model\n",
    "input_shape = IMG_SIZE #tf.keras.Input(shape=(48, 48, 1))\n",
    "output_shape = 46\n",
    "model = EfficientHiragana(input_shape, output_shape)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# freeze the 100 layers to fine-tuning\n",
    "model.trainable = True\n",
    "print(\"Number of layers in the base model: \", len(model.layers))\n",
    "# fine_tune_at = 100\n",
    "# for layer in model.layers[:fine_tune_at]:\n",
    "#   layer.trainable = False\n",
    "\n",
    "# train model \n",
    "epochs=5\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_dataset,\n",
    ")\n",
    "\n",
    "# model.save_weights('EfficientNetB0_Hiragana.h5')\n",
    "\n",
    "# model.build(input_shape=(None, IMG_SIZE, IMG_SIZE, 3))\n",
    "print(model.summary())\n",
    "\n",
    "# visualize the results\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8),facecolor='w')\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.savefig('results.png')\n",
    "plt.show()\n",
    "\n",
    "# evaluate the model using test_dataset\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "84c2839c7d4d48ea5711913a987869f1e4a28c463344043f871f5ee91cfcc339"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
